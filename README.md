# ISIScT_Dataset
Our dataset is meticulously constructed using three distinct methodologies to ensure diversity, realism, and robustness in scene text recognition. First, we captured real-world images using various mobile cameras, incorporating challenges such as curved, multi-oriented, and multilingual (English, Hindi, Bengali) text, along with distortions like blurring (caused by motion or defocus), uneven lighting (due to shadows or artificial sources), and occlusions (text partially hidden by objects). Additionally, perceptual distortions such as curved, angular, and irregularly shaped text are present, making character segmentation and recognition more complex. These images were taken from diverse locations, including city streets, railway platforms, and office buildings, during both day and night conditions to introduce natural illumination variations.  
To enhance robustness, we augmented open-source and collected images with synthetic environmental effects, such as fog (simulating faded visibility), rain (causing localized distortions), and intense sunlight (introducing glare and contrast reduction). Additionally, we curated publicly available images, focusing on curved, low-contrast, and multi-aligned text from signboards, memes, and posters, ensuring no post-processing for contrast or brightness adjustments.
Our dataset has 5,500 images with 6048 text areas, comprising 850 captured images, 850 synthetic versions with environmental impacts, and 3,800 synthetically altered images from TotalText (1,000), MLT19 Bengali-Hindi (2,000), and MLT17 Bengali (800). Text sections are defined as consecutive, readable lines, while misaligned words are segmented separately. 
